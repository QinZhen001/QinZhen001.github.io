---
layout:     post
title:      "网络协议相关"
date:       2019-01-19 19:29:00
author:     "Qz"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - Network
---

> “Yeah It's on. ”


# HTTP

[https://mp.weixin.qq.com/s/6DBhbz7eAETXVbPHmOKHww](https://mp.weixin.qq.com/s/6DBhbz7eAETXVbPHmOKHww)

## HTTP1.1


### HTTP1.1的缺陷
 
 
* 高延迟 — 队头阻塞(Head-Of-Line Blocking)
* 无状态特性 — 阻碍交互
* 明文传输 — 不安全性
* 不支持服务端推送


-----


**队头阻塞**


队头阻塞是指当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一并被阻塞，会导致客户端迟迟收不到数据。


针对队头阻塞：


1. 将同一页面的资源分散到不同域名下，提升连接上限。虽然能公用一个 TCP 管道，但是在一个管道中同一时刻只能处理一个请求，在当前的请求没有结束之前，其他的请求只能处于阻塞状态。
2. 减少请求数量
3. 内联一些资源：css、base64 图片等
4. 合并小文件减少资源数




----

**无状态特性**

**无状态是指协议对于连接状态没有记忆能力**。纯净的 HTTP 是没有 cookie 等机制的，每一个连接都是一个新的连接。上一次请求验证了用户名密码，而下一次请求服务器并不知道它与上一条请求有何关联，换句话说就是掉登录态。



-----


**不安全性**




传输内容没有加密，中途可能被篡改和劫持。


## SPDY 协议

SPDY 是由 google 推行的改进版本的 HTTP1.1 （那时候还没有 HTTP2）。

特性：


* 多路复用 — 解决队头阻塞
* 头部压缩 — 解决巨大的 HTTP 头部
* 请求优先级 — 先获取重要数据
* 服务端推送 — 填补空缺
* 提高安全性

---

**多路复用**

SPDY 允许在一个连接上无限制并发流。因为请求在一个通道上，TCP 效率更高。更少的网络连接，发出更密集的包。


---


**头部压缩**

使用专门的 HPACK 算法，每次请求和响应只发送差异头部，一般可以达到 50% ~90% 的高压缩率。



---


**请求优先级**


虽然无限的并发流解决了队头阻塞的问题，但如果带宽受限，客户端可能会因防止堵塞通道而阻止请求。在网络通道被非关键资源堵塞时，提高安全性
请求会被优先处理。




---


**服务端推送**


服务端推送（ServerPush），可以让服务端主动把资源文件推送给客户端。当然客户端也有权利选择是否接收。





---

**提高安全性**


支持使用 HTTPS 进行加密传输。




## HTTP2


HTTP2 基于 SPDY，专注于性能，最大的一个目标是在用户和网站间只用一个连接。




新增特性：

* 二进制分帧 - HTTP2 性能增强的核心
* 多路复用 - 解决串行的文件传输和连接数过多


---

**二进制分帧**



首先，HTTP2 没有改变 HTTP1 的语义，只是在应用层使用二进制分帧方式传输。因此，也引入了新的通信单位：**帧、消息、流**。

分帧有什么好处？服务器单位时间接收到的请求数变多，可以提高并发数。最重要的是，为多路复用提供了底层支持。


----



**多路复用**




一个域名对应一个连接，一个流代表了一个完整的**请求-响应**过程。帧是最小的数据单位，每个帧会标识出该帧属于哪个流，流也就是多个帧组成的数据流。多路复用，就是在一个 TCP 连接中可以存在多个流。


-----


### HTTP2 的缺陷


* TCP 以及 TCP+TLS 建立连接的延时
* TCP 的队头阻塞并没有彻底解决
* 多路复用导致服务器压力上升
* 多路复用容易 Timeout




----



**多路复用导致服务器压力上升**

多路复用没有限制同时请求数。请求的平均数量与往常相同，但实际会有许多请求的短暂爆发，导致瞬时 QPS 暴增。



-----

**多路复用容易 Timeout**



大批量的请求同时发送，由于 HTTP2 连接内存在多个并行的流，而网络带宽和服务器资源有限，每个流的资源会被稀释，虽然它们开始时间相差更短，但却都可能超时。

即使是使用 Nginx 这样的负载均衡器，想正确进行节流也可能很棘手。其次，就算你向应用程序引入或调整排队机制，但一次能处理的连接也是有限的。如果对请求进行排队，还要注意在响应超时后丢弃请求，以避免浪费不必要的资源。







