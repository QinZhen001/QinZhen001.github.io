---
layout:     post
title:      "网络知识相关"
date:       2019-01-19 19:29:00
author:     "Qz"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - Network
---

> “Yeah It's on. ”


# 网络协议

[https://mp.weixin.qq.com/s/6DBhbz7eAETXVbPHmOKHww](https://mp.weixin.qq.com/s/6DBhbz7eAETXVbPHmOKHww)



## HTTP1.1

如果页面中发起了多个http请求，此时只需要建立一个tcp连接就可以了，多个http请求响应会共用这一个tcp连接通道。





### 管道化

[https://cloud.tencent.com/developer/article/1509279](https://cloud.tencent.com/developer/article/1509279)

> 管线化机制须通过永久连接（persistent connection）完成，仅HTTP/1.1支持此技术（HTTP/1.0不支持）

在使用持久连接的情况下，某个连接消息的传递类似于

* 请求1 -> 响应1 -> 请求2 -> 响应2

管线化：某个连接上的消息变成了类似这样 

* 请求1 -> 请求2 -> 请求3 -> 响应1 -> 响应2 -> 响应3



**持久连接的一个缺点是请求和响应式是顺序执行的**，只有在请求1的响应收到之后，才会发送请求2，而管线化不需要等待上一次请求得到响应就可以进行下一次请求。实现并行发送请求。 



**只有GET和HEAD要求可以进行管线化，而POST则有所限制**







管道化要求服务端按照请求发送的顺序返回响应（FIFO），原因很简单，HTTP请求和响应并没有序号标识，无法将乱序的响应与请求关联起来。



当客户端在支持管道化时需要保持未收到响应的请求，当连接意外中断时，需要重新发送这部分请求。如果这个请求只是从服务器获取数据，那么并不会对资源造成任何影响，而如果是一个提交信息的请求如post请求，那么可能会造成资源多次提交从而改变资源，这是不允许的。而不会对服务器资源产生影响的请求有个专业名词叫做幂等请求。客户端在使用管道化的时候请求方式必须是幂等请求。



因为HTTP管道化本身可能会导致队头阻塞的问题，以及上面提到的一些限制，**现代浏览器默认都关闭了管道化，并且大部分服务器也是默认不支持管道化的**。





### HTTP1.1的缺陷


* 高延迟 — 队头阻塞(Head-Of-Line Blocking)
* 无状态特性 — 阻碍交互
* 明文传输 — 不安全性
* 不支持服务端推送

-----

#### **队头阻塞**


队头阻塞是指当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一并被阻塞，会导致客户端迟迟收不到数据。


针对队头阻塞：


1. 将同一页面的资源分散到不同域名下，提升连接上限。虽然能**公用一个 TCP 管道**，但是在一个管道中同一时刻只能处理一个请求，在当前的请求没有结束之前，其他的请求只能处于阻塞状态。
2. 减少请求数量
3. 内联一些资源：css、base64 图片等
4. 合并小文件减少资源数





> 客户端建立长连接的个数是针对域名发起的，举例说明，当我们访问a.com网站的时候，客户端与a.com服务器建立的长链接就是2个。但是一般浏览器会把并发链接数增加到6到8个，谷歌浏览器是6个





----

#### **无状态特性**

**无状态是指协议对于连接状态没有记忆能力**。纯净的 HTTP 是没有 cookie 等机制的，每一个连接都是一个新的连接。上一次请求验证了用户名密码，而下一次请求服务器并不知道它与上一条请求有何关联，换句话说就是掉登录态。



-----

#### **不安全性**




传输内容没有加密，中途可能被篡改和劫持。


## SPDY 协议

SPDY 是由 google 推行的改进版本的 HTTP1.1 （那时候还没有 HTTP2）。

特性：


* 多路复用 — 解决队头阻塞
* 头部压缩 — 解决巨大的 HTTP 头部
* 请求优先级 — 先获取重要数据
* 服务端推送 — 填补空缺
* 提高安全性

---

**多路复用**

SPDY 允许在一个连接上无限制并发流。因为请求在一个通道上，TCP 效率更高。更少的网络连接，发出更密集的包。

---


**头部压缩**

使用专门的 HPACK 算法，每次请求和响应只发送差异头部，一般可以达到 50% ~90% 的高压缩率。



---


**请求优先级**


虽然无限的并发流解决了队头阻塞的问题，但如果带宽受限，客户端可能会因防止堵塞通道而阻止请求。在网络通道被非关键资源堵塞时，提高安全性
请求会被优先处理。



---


**服务端推送**


服务端推送（ServerPush），可以让服务端主动把资源文件推送给客户端。当然客户端也有权利选择是否接收。





---

**提高安全性**


支持使用 HTTPS 进行加密传输。




## HTTP2


HTTP2 基于 SPDY，专注于性能，最大的一个目标是在用户和网站间只用一个连接。




新增特性：

* 二进制分帧 - HTTP2 性能增强的核心
* 多路复用 - 解决串行的文件传输和连接数过多

---

**二进制分帧**



首先，HTTP2 没有改变 HTTP1 的语义，只是在应用层使用二进制分帧方式传输。因此，也引入了新的通信单位：**帧、消息、流**。

分帧有什么好处？服务器单位时间接收到的请求数变多，可以提高并发数。最重要的是，为多路复用提供了底层支持。

----



**多路复用**




一个域名对应一个连接，一个流代表了一个完整的**请求-响应**过程。帧是最小的数据单位，每个帧会标识出该帧属于哪个流，流也就是多个帧组成的数据流。多路复用，就是在一个 TCP 连接中可以存在多个流。

-----


### HTTP2 的缺陷


* TCP 以及 TCP+TLS 建立连接的延时
* TCP 的队头阻塞并没有彻底解决
* 多路复用导致服务器压力上升
* 多路复用容易 Timeout



----



**多路复用导致服务器压力上升**

多路复用没有限制同时请求数。请求的平均数量与往常相同，但实际会有许多请求的短暂爆发，导致瞬时 QPS 暴增。



-----

**多路复用容易 Timeout**



大批量的请求同时发送，由于 HTTP2 连接内存在多个并行的流，而网络带宽和服务器资源有限，每个流的资源会被稀释，虽然它们开始时间相差更短，但却都可能超时。

即使是使用 Nginx 这样的负载均衡器，想正确进行节流也可能很棘手。其次，就算你向应用程序引入或调整排队机制，但一次能处理的连接也是有限的。如果对请求进行排队，还要注意在响应超时后丢弃请求，以避免浪费不必要的资源。







## **OAuth**

[http://www.ruanyifeng.com/blog/2019/04/oauth_design.html](http://www.ruanyifeng.com/blog/2019/04/oauth_design.html)



**简单说，OAuth 就是一种授权机制。数据的所有者告诉系统，同意授权第三方应用进入系统，获取这些数据。系统从而产生一个短期的进入令牌（token），用来代替密码，供第三方应用使用。**



> OAuth 引入了一个授权层，用来分离两种不同的角色：客户端和资源所有者。......资源所有者同意以后，资源服务器可以向客户端颁发令牌。客户端通过令牌，去请求数据。





# 缓存





### **Provisional headers are shown**

[https://www.jianshu.com/p/4cfa40121ecf](https://www.jianshu.com/p/4cfa40121ecf)



 Request Headers 中发现存在 Provisional headers are shown 的警告



这个问题字面意思是“显示了临时报文头”，浏览器第一次发送这个请求，请求被阻塞，未收到响应。当要求浏览器再次发送这个请求时，上个同样的请求都还没有收到响应，浏览器就会报这个警告。



---





**该数据直接采用了缓存，并没有发送请求**



只从缓存中获得的通信显示为“显示临时标题”（或“执行”），因为该文件是从缓存中获取的，并且未进行通信，所以并不会显示详细标头。

如果上一个资源加载失败，可能导致从缓存加载的资源失败，即缓存资源请求之前的请求不能失败。强缓存from disk cache或者from memory cache，此时也不会显示。



其实都是与服务器没有进行或者完成正确的通信，所以只展示临时信息。





### X-Cache Header

[https://stackoverflow.com/questions/3027492/x-cache-header-explanation](https://stackoverflow.com/questions/3027492/x-cache-header-explanation)





`CDN` (`Content Delivery Network`) adds `X-cache` header to HTTP Response. `X-cache:HIT` means that your request was served by CDN, not origin servers. CDN is a special network designed to cache content, so that usr request served faster + to unload origin servers.



CDN(内容传递网络)将X-cache头添加到HTTP响应中。x -高速缓存:命中意味着你的请求是由CDN服务的，而不是源服务器。CDN是一种特殊的网络，旨在缓存内容，使usr请求服务更快+卸载源服务器。



Furthermore, there are a bunch of "X- " headers provided by CDNs. They indicate HIT, MISS etc. You can simply install firebug plugin in firefox and request some progressive download video, probably it'll be served by cdn node, so the HOST header in response might contain smth like cdn.rt.com and there will be "X- " headers



此外，CDNs还提供了一堆“X-”头信息。它们表示命中、未命中等。你可以简单地在firefox中安装firebug插件并请求一些渐进的下载视频，可能它会被cdn节点服务，所以主机头响应可能包含smth像cdn.rt.com，将有“X-”头



> **X-Cache** corresponds to the result, whether the proxy has served the result from cache (HIT for yes, and MISS for no)
>
> X-Cache与结果相对应，无论代理是否已从缓存提供结果（HIT为是，MISS为否）











# 补充



## options 请求



[ https://juejin.im/post/5edef7b2e51d45784213ca24?utm_source=gold_browser_extension ]( https://juejin.im/post/5edef7b2e51d45784213ca24?utm_source=gold_browser_extension )



> HTTP 的 OPTIONS 方法 用于获取目的资源所支持的通信选项。客户端可以对特定的 URL 使用 OPTIONS 方法，也可以对整站（通过将 URL 设置为"*"）使用该方法。



**简单来说，就是可以用 options 请求去嗅探某个请求在对应的服务器中都支持哪种请求方法。**



 在前端中我们一般不会主动发起这个请求，  是在跨域的情况下，浏览器发起"复杂请求"时主动发起的。 



> 某些请求不会触发 CORS 预检请求，这样的请求一般称为"简单请求",而会触发预检的请求则成为"复杂请求"。





跨域共享标准规范要求，对那些可能对服务器数据产生副作用的 HTTP 请求方法（特别是 GET 以外的 HTTP 请求，或者搭配某些 MIME 类型的 POST 请求），浏览器必须首先使用 OPTIONS 方法发起一个预检请求（preflight request），从而获知服务端是否允许该跨域请求。服务器确认允许之后，才发起实际的 HTTP 请求。

### 

#### 简单请求

- 请求方法为`GET、HEAD、POST`时发的请求
- 人为设置了规范集合之内的首部字段，如`Accept/Accept-Language/Content-Language/Content-Type/DPR/Downlink/Save-Data/Viewport-Width/Width`
- `Content-Type` 的值仅限于下列三者之一,即`application/x-www-form-urlencoded、multipart/form-data、text/plain`
- 请求中的任意 XMLHttpRequestUpload 对象均没有注册任何事件监听器；
- 请求中没有使用 ReadableStream 对象。

#### 

#### 复杂请求

- 使用了下面任一 HTTP 方法，PUT/DELETE/CONNECT/OPTIONS/TRACE/PATCH
- 人为设置了以下集合之外首部字段，即简单请求外的字段
- Content-Type 的值不属于下列之一，即`application/x-www-form-urlencoded、multipart/form-data、text/plain`

### 

#### options 关键的请求头字段





request header 的关键字段

| 关键字段                       | **作用**                                       |
| :----------------------------- | ---------------------------------------------- |
| Access-Control-Request-Method  | 告知服务器，实际请求将使用 POST 方法           |
| Access-Control-Request-Headers | 告知服务器，实际请求将携带的自定义请求首部字段 |



如：

```
Access-Control-Request-Method: POST
Access-Control-Request-Headers: X-PINGOTHER, Content-Type
```



response header 的关键字段



| 关键字段                     | 作用                                             |
| ---------------------------- | ------------------------------------------------ |
| Access-Control-Allow-Methods | 表明服务器允许客户端使用什么方法发起请求         |
| Access-Control-Allow-Origin  | 允许跨域请求的域名，如果要允许所有域名则设置为 * |
| Access-Control-Allow-Headers | 将实际请求所携带的首部字段告诉服务器             |
| Access-Control-Max-Age       | 指定了预检请求的结果能够被缓存多久               |





#### Options 请求优化



当我们发起跨域请求时，如果是简单请求，那么我们只会发出一次请求，但是如果是复杂请求则先发出 options 请求，用于确认目标资源是否支持跨域，然后浏览器会根据服务端响应的 header 自动处理剩余的请求，如果响应支持跨域，则继续发出正常请求，如果不支持，则在控制台显示错误。



由此可见，当触发预检时，跨域请求便会发送 2 次请求，既增加了请求数，也延迟了请求真正发起的时间，严重影响性能。



所以，我们可以优化 Options 请求，主要有 2 种方法。

  



1.  转为简单请求，如用 JSONP 做跨域请求
2.  对 options 请求进行缓存，服务器端设置 `Access-Control-Max-Age` 字段，那么当第一次请求该 URL 时会发出 OPTIONS 请求，浏览器会根据返回的 Access-Control-Max-Age 字段缓存该请求的 OPTIONS 预检请求的响应结果（具体缓存时间还取决于浏览器的支持的默认最大值，取两者最小值，一般为 10 分钟）。在缓存有效期内，该资源的请求（URL 和 header 字段都相同的情况下）不会再触发预检。（chrome 打开控制台可以看到，当服务器响应 Access-Control-Max-Age 时只有第一次请求会有预检，后面不会了。注意要开启缓存，去掉 disable cache 勾选。）





#### 总结



options 请求就是预检请求，可用于检测服务器允许的 http 方法。当发起跨域请求时，由于安全原因，触发一定条件时浏览器会在正式请求之前自动先发起 OPTIONS 请求，即 CORS 预检请求，服务器若接受该跨域请求，浏览器才继续发起正式请求。



##  **Vary** 



[ https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Vary ]( https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Vary )



 **`Vary`** 是一个HTTP响应头部信息，它决定了对于未来的一个请求头，应该用一个缓存的回复(response)还是向源服务器请求一个新的回复   **（和缓存有关系）**



Vary出现在响应信息中的作用是什么呢？**首先这是由服务器端添加，添加到响应头部。**大部分情况下是用在客户端缓存机制或者是缓存服务器在做缓存操作的时候，会使用到Vary头，会读取响应头中的Vary的内容，进行一些缓存的判断。



Vary的字面意思是“不一、多样化”，顾名思义，它的存在区分同样的网络请求的不同之处，其实就是通过头部信息来区分。Vary存在于响应头中，它的内容来自于请求头中相关字段



缓存服务器会将某接口的首次请求结果缓存下来**（包括响应头中的Vary）**，后面在发生相同请求的时候缓存服务器会拿着缓存的Vary来进行判断。比如Vary: Accept-Encoding,User-Agent，那么Accept-Encoding与User-Agent两个请求头的内容，就会作为判断是否返回缓存数据的依据，当缓存服务器中相同请求的缓存数据的编码格式、代理服务与当前请求的编码格式、代理服务一致，那就返回缓存数据，否则就会从服务器重新获取新的数据。当缓存服务器中已经缓存了该条请求，那么某次服务器端的响应头中如果Vary的值改变，则Vary会更新到该请求的缓存中去，下次请求会对比新的Vary内容。



官方解释Vary头：告知下游的代理服务器，应当如何对以后的请求协议头进行匹配，以决定是否可使用已缓存的响应内容而不是重新从原服务器请求新的内容。



> Vary: * ，这个我不太理解，我个人的理解是，当Vary的值为“*”时，意味着请求头中的那些字段的值不能用来区分当前请求是从缓存服务拿还是重新请求获取，在Android的OkHttp框架中，客户端接收到服务器的响应数据，进行缓存处理时，一旦判断响应头有Vary:*时，就不缓存该条数据。所以我猜想缓存服务器会不会也是这样，当Vary的值为“*”时，不做缓存。
>



 它被服务器用来表明在 [content negotiation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Content_negotiation) algorithm（内容协商算法）中选择一个资源代表的时候应该使用哪些头部信息（headers）. 



在响应状态码为 [`304`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/304) `Not Modified` 的响应中，也要设置 Vary 首部，而且要与相应的 [`200`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/200) `OK` 响应设置得一模一样。



-----



#### 条件型 CORS 响应下的缓存错乱问题



[ https://zhuanlan.zhihu.com/p/38972475 ]( https://zhuanlan.zhihu.com/p/38972475 )



[图片出现 不能跨域的缓存 ]( https://www.ccc5.cc/2375.html )



在 @koa/cors 中



我们发现



```js
    // Always set Vary header
    // https://github.com/rs/cors/issues/10
    ctx.vary('Origin');
```



这是为了解决**条件型 CORS 响应下的缓存错乱问题**







比如在同一个浏览器下，先打开了`foo.taobao.com`上的一个页面，访问了我们的资源，这个资源被浏览器缓存了下来，和资源内容一起缓存的还有`Access-Control-Allow-Origin: https://foo.taobao.com`响应头。这时又打开 `bar.taobao.com`上的一个页面，这个页面也要访问那个资源，这时它会读取本地缓存，读到的 `Access-Control-Allow-Origin`头是缓存下的 `https://foo.taobao.com` 而不是自己想要的 `https://bar.taobao.com`，这时就报跨域错误了，虽然它应该是能访问到这份资源的。



上面举的例子是“区分对待不同的`Origin`请求头”这类条件型 CORS 响应下引起的缓存错乱，这种问题是需要用户访问多个网站（`foo.taobao.com`和`bar.taobao.com`）后才可能触发的问题。“区分对待有无`Origin`请求头”也可能会造成类似的问题，而且在同一个站点下就有可能触发，比如用户先访问了`foo.taobao.com`的一个页面 A，页面 A 里用``标签加载了一张图片，注意这时候这张图片已经被浏览器缓存了，并且缓存里没有 `Access-Control-Allow-Origin`响应头，因为``发起的请求不带`Origin`请求头，此时用户又访问了`foo.taobao.com`的另一个页面 B，页面 B 里用 XHR 请求同一张图片，结果读了缓存，没有发现 CORS 响应头，报了跨域错误。在一些场景下，页面 A 和页面 B 有可能会是同一个页面，也就是说在同一个页面里就有可能触发这个问题。



**使用 Vary: Origin 让同一个 URL 有多份缓存**



有一个 HTTP 响应头叫`Vary`，vary 这个单词的意思是“变化”、“不同”的意思，**`Vary`响应头就是让同一个 URL 根据某个请求头的不同而使用不同的缓存**。比如常见的`Vary: Accept-Encoding`表示客户端要根据`Accept-Encoding`请求头的不同而使用不同的缓存，比如 gizp 的缓存一份，未压缩的缓存为另一份。



在 CORS 的场景下，我们需要使用`Vary: Origin`来保证不同网站发起的请求使用各自的缓存。比如从`foo.taobao.com`发起的请求缓存下的响应头是：




```text
Access-Control-Allow-Origin: https://foo.taobao.com
Vary: Origin
```



`bar.taobao.com`在发起同 URL 的请求就不会使用这份缓存了，因为`Origin`请求头变了。还有``标签发起的非 CORS 请求缓存下的响应头是：




 ```
Vary: Origin
 ```



 在使用 XHR 发起的 CORS 请求也不会使用那份缓存，因为`Origin`请求头从无到有，也算是变了。 





> If CORS protocol requirements are more complicated than setting `Access-Control-Allow-Origin` to * or a static origin, `Vary` is to be used 
>
> 
>
> 翻译一下就是“如果你的 `Access-Control-Allow-Origin`响应头不是简单的写死成了`*`或者某一个特定的源（就是我总结的条件型 CORS 响应），那么你就应该加上`Vary: Origin`响应头。





## withCredentials

[ https://developer.mozilla.org/zh-CN/docs/Web/API/XMLHttpRequest/withCredentials ]( https://developer.mozilla.org/zh-CN/docs/Web/API/XMLHttpRequest/withCredentials )



> **一个很重要的点： withCredentials永远不会影响到同源请求** 



 **XMLHttpRequest.withCredentials**  属性是一个[`Boolean`](https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Boolean)类型，它指示了是否该使用类似cookies,authorization headers(头部授权)或者TLS客户端证书这一类资格证书来创建一个跨站点访问控制（cross-site `Access-Control`）请求。 



在同一个站点下使用`withCredentials属性是无效的。`





`此外，这个指示`也会被用做`响应中`cookies 被忽视的标示。默认值是false。



如果在发送来自其他域的XMLHttpRequest请求之前，未设置`withCredentials` 为true，那么就不能为它自己的域设置cookie值。而通过设置`withCredentials` 为true获得的第三方cookies，将会依旧享受同源策略，因此不能被通过[document.cookie](https://developer.mozilla.org/en-US/docs/Web/API/Document/cookie)或者从头部相应请求的脚本等访问。



> 不同域下的`XmlHttpRequest` 响应，不论其`Access-Control-header` 设置什么值，都无法为它自身站点设置cookie值，除非它在请求之前将`withCredentials` 设为true。  





## jwt相关

jwt可以用于验证用户身份信息，和传统的token作用差不多。



传统的token是服务端将用户信息进行MD5处理发送给客户端，客户端在请求时带上token验证。因为MD5是不可逆的，服务端需要去数据库查询相关用户信息，再进行一次MD5，用该MD5和客户端发来的MD5进行对比。



而jwt是不需要服务端经过数据库查询的操作，jwt有对应的加密解密算法，服务端拿到jwt后通过密钥解密可以把其中的用户信息拿到。



#### 优势

**无状态**

由于 JWT 是自包含的，且无需在内存中保持请求之间的令牌，所以应用服务器可以做到完全无状态（stateless）。认证服务器可以颁发令牌，将其发回后就立即丢弃掉。

**紧凑**

JSON 比 XML 简介，所以当其被编码后，一个 JWT 比 SAML 令牌更小。这使得 JWT 成为一个在 HTML 和 HTTP 环境中传送的好选择。

**更安全**





## oauth2.0

**OAuth协议，是一种授权协议，不涉及具体的代码，只是表示一种约定的流程和规范。OAuth协议一般用于用户决定是否把自己在某个服务商上面的资源（比如：用户基本资料、照片、视频等）授权给第三方应用访问**。此外，OAuth2.0协议是OAuth协议的升级版，现在已经逐渐成为单点登录（SSO）和用户授权的标准。



* **第一，用户不再需要注册大量账号。**在以前，我们每使用一个新的网站或者APP就需要注册一个账号，建立一套新的账户体系才能使用网站 / APP提供的服务。但是现在我们只需要拥有几个主流应用的账号，然后通过他们提供的第三方账号登录就可以使用一个新的网站/APP了（当然，我们也可以不使用腾讯百度等公司提供的授权服务，开发自己的授权服务端，这方面的内容我将放在下篇文章中介绍）。
* **第二，用于单点登录。**如果某个公司有很多个需要用户登录才能提供服务的子产品（比如：官网、M网站、APP、微信公众号、使用同一套账户体系的产品1、产品2等等），这种情况下为每个产品都开发一个登录、授权模块显然是不太优雅，因此比较好的解决方案就是所有需要登录的产品都请求同一个登录授权中心，进行统一登录授权处理。而OAuth2.0协议就可以实现符合上述要求的单点登录功能。
* **第三，用于分布式系统的权限控制。**因为基于OAuth2.0协议获得的令牌（Access Token）同时关联了接入的第三方应用、授权用户、权限范围等信息。因此，在第三方应用拿着Token请求资源的时候，资源服务应用就可以很容易根据其访问权限返回相应的数据。



----



使用授权码模式完成OAuth2.0授权的过程需要以下三个步骤：

1. client请求授权服务端，**获取Authorization Code**；
2. client通过Authorization Code再次请求授权服务端，**获取Access Token**；
3. client通过服务端返回的Access Token**获取用户的基本信息**。





